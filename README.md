# Awesome-AI-Papers [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

Collect **0-10** the most impressive AI papers each year. **Actively keep updating**


## Papers
### 2025
- [2025] Qwen3 Technical Report (**Qwen3**). [[paper](https://arxiv.org/pdf/2505.09388?)]
- [2025] DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning (**DeepSeek-R1**). [[paper](https://arxiv.org/pdf/2408.03314)]
- [2025] Kimi K1.5: Scaling Reinforcement Learning with LLMs (**Kimi K1.5**). [[paper](https://arxiv.org/pdf/2501.12599?)]
### 2024
- [2024] Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters. [[paper](https://arxiv.org/pdf/2407.21783)]
- [2024] The Llama 3 Herd of Models (**Llama 3**). [[paper](https://arxiv.org/pdf/2407.21783)]
- [2024] Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context (**Gemini 1.5**). [[paper](https://arxiv.org/pdf/2403.05530)]
- [2024] Mixtral of Experts (**SMoE**). [[paper](https://arxiv.org/pdf/2403.05530)]
- [2024] Phi-3 technical report: A highly capable language model locally on your phone (**PHI**). [[paper](https://arxiv.org/pdf/2404.14219)]
- [2024] A survey on evaluation of large language models(**Survey**). [[paper](https://dl.acm.org/doi/pdf/10.1145/3641289)]
- [2024] Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Models(**VIM**). [[paper](https://arxiv.org/pdf/2401.09417)]
- [2024] DeepSeek-V3 Technical Report (**DeepSeek-V3**). [[paper](https://arxiv.org/abs/2412.19437)]
### 2023
- [2023] GPT-4 Technical Report (**GPT-4**). [[paper](https://arxiv.org/pdf/2303.08774)]
- [2023] Llama 2: Open Foundation and Fine-Tuned Chat Models(**LLaMa 2**). [[paper](https://arxiv.org/pdf/2307.09288)]
- [2023] Mamba: Linear-time sequence modeling with selective state spaces (**Mamba**). [[paper](https://minjiazhang.github.io/courses/fall24-resource/Mamba.pdf)]
- [2023] LLaMA: Open and Efficient Foundation Language Models (**LLaMa**). [[paper](https://arxiv.org/pdf/2302.13971)]
- [2023] QLoRA: Efficient Finetuning of Quantized LLMs (**QLoRA**). [[paper](https://arxiv.org/abs/2305.14314)]
- [2023] Gemini: A Family of Highly Capable Multimodal Models(**Gemini**). [[paper](https://arxiv.org/pdf/2312.11805)]
- [2023] Qwen Technical Report (**Qwen**). [[paper](https://arxiv.org/pdf/2309.16609)]
- [2023] PaLM: Scaling Language Modeling with Pathways (**PaLM, JMLR 2023**). [[paper](https://www.jmlr.org/papers/volume24/22-1144/22-1144.pdf)]
### 2022
- [2022] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (**CoT**). [[paper](https://arxiv.org/pdf/2201.11903)]
- [2022] Training language models to follow instructions with human feedback (**InstructGPT, GPT-3.5**). [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf)]
- [2022] Masked Autoencoders Are Scalable Vision Learners (**MAE, CVPR 2022**).  [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf)]
- [2022] High-Resolution Image Synthesis with Latent Diffusion Models (**StableDiffusion, CVPR 2022**). [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)]
- [2022] LoRA: Low-Rank Adaptation of Large Language Models (**ICLR 2022**). [[paper](https://arxiv.org/pdf/2106.09685v1/1000)]
- [2022] Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding(**NeurIPS 2022**). [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/ec795aeadae0b7d230fa35cbaf04c041-Paper-Conference.pdf)]
### 2021
- [2021] Emerging Properties in Self‑Supervised Vision Transformers(**DINO**). [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.pdf)]
- [2021] Highly accurate protein structure prediction with AlphaFold (**Nature 2021**). [[paper](https://www.nature.com/articles/s41586-021-03819-2)]
- [2021] Hierarchical Vision Transformer using Shifted Windows (**Swin, ICCV 2021**). [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf)]
- [2021] An image is worth 16x16 words: Transformers for image recognition at scale (**ViT, ICLR 2021**). [[paper](https://arxiv.org/pdf/2010.11929)]
- [2021] Learning Transferable Visual Models From Natural Language Supervision (**CLIP, ICML 2021**). [[paper](https://proceedings.mlr.press/v139/radford21a/radford21a.pdf)]
- [2021] Zero-Shot Text-to-Image Generation(**PMLR 2021**). [[paper](https://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf)]
- [2021] Evaluating Large Language Models Trained on Code(**Codex**). [[paper](https://arxiv.org/pdf/2107.03374)]
### 2020
- [2020] End-to-end object detection with transformers(**DETR, ECCV 2020**). [[paper](https://arxiv.org/pdf/2005.12872)]
- [2020] Language Models are Few-Shot Learners (**GPT-3, NeurIPS 2020**). [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)]
- [2020] Denoising Diffusion Probabilistic Models (**Diffusion, NeurIPS 2020**). [[paper](https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf)]
- [2020] YOLOv4: Optimal Speed and Accuracy of Object Detection(**YOLOv4**). [[paper](https://arxiv.org/pdf/2004.10934)]
- [2020] Exploring the limits of transfer learning with a unified text-to-text transformer(**T5**). [[paper](https://www.jmlr.org/papers/volume21/20-074/20-074.pdf)]
- [2020] Efficientdet: Scalable and efficient object detection (**ICCV 2020**). [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_EfficientDet_Scalable_and_Efficient_Object_Detection_CVPR_2020_paper.pdf)]
- [2020] A Simple Framework for Contrastive Learning of Visual Representations (**ICML 2020**). [[paper](https://proceedings.mlr.press/v119/chen20j/chen20j.pdf)]
- [2020] ALBERT: A Lite BERT for Self-supervised Learning of Language Representations(**ICLR 2020**). [[paper](https://arxiv.org/pdf/1909.11942)]

### 2000-2019
- [2019] Language Models are Unsupervised Multitask Learners (**GPT-2**). [[paper](https://storage.prod.researchhub.com/uploads/papers/2020/06/01/language-models.pdf)]
- [2019] Decoupled Weight Decay Regularization (**AdamW, ICLR 2019**). [[paper](https://arxiv.org/pdf/1711.05101)]
- [2018] BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension (**BART**). [[paper](https://arxiv.org/pdf/1910.13461)]
- [2018] Improving language understanding by generative pre-training (**GPT-1**). [[paper](https://www.mikecaptain.com/resources/pdf/GPT-1.pdf)]
- [2018] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (**Bert**). [[paper](https://arxiv.org/pdf/1810.04805)]
- [2017] Mastering the game of Go without human knowledge (**AlphaGOZero, Nature 2017**). [[paper](https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ)]
- [2017] Attention Is All You Need (**Transformer, NeurIPS 2017**). [[paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)]
- [2017] Pointnet: Deep learning on point sets for 3d classification and segmentation (**PointNet, CVPR 2017**). [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Qi_PointNet_Deep_Learning_CVPR_2017_paper.pdf)]
- [2017] Mask R-CNN (**ICCV 2017**). [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/He_Mask_R-CNN_ICCV_2017_paper.pdf)]
- [2016] Neural Architecture Search with Reinforcement Learning (**NAS**). [[paper](https://arxiv.org/pdf/1611.01578)] 
- [2016] Mastering the game of Go with deep neural networks and tree search (**AlphaGo, Nature 2016**). [[paper](https://d1wqtxts1xzle7.cloudfront.net/82684593/2016_20go-libre.pdf?1648263964=&response-content-disposition=inline%3B+filename%3DMastering_the_game_of_Go_with_deep_neura.pdf&Expires=1740109551&Signature=WCGaYHwuy0~IXoJvuq5h6msbjWEBjz09nlyWff1veTS-0ZSEMuzsMAgNHa2gpg7Zn8f4FDMocDgXhkPqQqcjxFtTg-wZStEq-yUjBhcGXdBs1ugjf-YamzrIK669MOnhUnhMTqM6b700nyIVUu2vK5aQYoikt7YyTLX2dmDZfUNL~HQLaTsjxjy50KBVb5KUhUBMq5LOLueqeNcwwXA0H6JkwcFpqOjNAC8q7gwtiStO9sIysyrG-IFFAOrh3ozNOoP8NlhReoKBbA2-6Gb8mfeA156f7M9Fyb5ZiYG1bxRTb9S3M4MsD10V7qNjZQrsdcTzDRfxmvsYBt2K5jARyg__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)]
- [2016] Deep Residual Learning for Image Recognition (**ResNet, CVPR 2016**). [[paper](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)]
- [2016] You only look once: Unified, real-time object detection (**YOLO, CVPR 2016**). [[paper](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf)]
- [2015] Deep learning (**Nature 2015**). [[paper](https://hal.science/hal-04206682/document)]
- [2015] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (**BN, ICML 2015**). [[paper](https://proceedings.mlr.press/v37/ioffe15.pdf)]
- [2015] Adam: A Method for Stochastic Optimization (**Adam**). [[paper](https://arxiv.org/pdf/1412.6980)]
- [2015] U-Net: Convolutional Networks for Biomedical Image Segmentation (**U-Net**). [[paper](https://arxiv.org/pdf/1505.04597)] 
- [2015] Very deep convolutional networks for large-scale image recognition (**VGG, ICLR 2015**). [[paper](https://arxiv.org/pdf/1409.1556)]
- [2014] Generative Adversarial Nets (**GAN, NeurIPS 2014**). [[paper](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)]
- [2014] Neural Machine Translation by Jointly Learning to Align and Translate (**Attention**). [[paper](https://arxiv.org/pdf/1409.0473)]
- [2014] Dropout: a simple way to prevent neural networks from overfitting (**Dropout**). [[paper](https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)]
- [2014] Sequence to Sequence Learning with Neural Networks (**Seq2seq, NeurIPS 2014**). [[paper](https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf)]
- [2014] Distilling the Knowledge in a Neural Network (**Knowledge Distillation**). [[paper](https://arxiv.org/pdf/1503.02531)]
- [2013] Distributed Representations of Words and Phrases and their Compositionality (**word2vec, NeurIPS 2013**). [[paper](https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf)]
- [2013] Playing Atari with Deep Reinforcement Learning (**Q-learning**). [[paper](https://arxiv.org/pdf/1312.5602)]
- [2013] auto-encoding variational bayes (**VAE**). [[paper](http://web2.cs.columbia.edu/~blei/fogm/2018F/materials/KingmaWelling2013.pdf)]
- [2012] Imagenet classification with deep convolutional neural networks (**AlexNet, NeurIps 2012**). [[paper](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)]
- [2011] Deep Sparse Rectifier Neural Networks (**ReLU**). [[paper](https://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf)]
- [2009] Imagenet: A large-scale hierarchical image database  (**CVPR 2009**). [[paper](https://hal.science/hal-03926082/document)]
### 1986-2000
- [1998] Gradient-based learning applied to document recognition (**CNN, Proceedings of the IEEE 1998**). [[paper](https://hal.science/hal-03926082/document)]
- [1997] Long Short-Term Memory (**LSTM, Neural Computation 1997**). [[paper](https://ieeexplore.ieee.org/abstract/document/6795963)]
- [1990] Finding Structure in Time (**RNN**). [[paper](https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog1402_1)]
- [1986] Learning internal representations by error propagation (**BP, Biometrika 1986**). [[paper](https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/pdfs/Chap8_PDP86.pdf)]

## Notice
- The collection of papers is somewhat subjective and limited in knowledge. Sorry for any possible omissions.
- Before this list, there exist [[another awesome deep learning list](https://github.com/terryum/awesome-deep-learning-papers/tree/master)].
